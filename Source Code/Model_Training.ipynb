{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8546ef96-5fd8-4e12-ba7b-88e9c33daaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/26 12:24:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/05/26 12:24:28 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/05/26 12:24:28 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"CyberSecurityThreatDetection\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb59cfc-9d48-4bbe-b4d5-ddc4eecc66dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>Fwd Pkt Len Mean</th>\n",
       "      <th>Fwd Pkt Len Std</th>\n",
       "      <th>...</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "      <th>Src IP</th>\n",
       "      <th>Src Port</th>\n",
       "      <th>Dst IP</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>10278</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DDOS attack-HOIC</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SSH-Bruteforce</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SSH-Bruteforce</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>101638</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Infilteration</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80</td>\n",
       "      <td>119927451</td>\n",
       "      <td>119775</td>\n",
       "      <td>0</td>\n",
       "      <td>3832800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DDOS attack-LOIC-UDP</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dst Port  Flow Duration  Tot Fwd Pkts  Tot Bwd Pkts  TotLen Fwd Pkts  \\\n",
       "0        80          10278             2             0              0.0   \n",
       "1        22             18             1             1              0.0   \n",
       "2        22              6             1             1              0.0   \n",
       "3        53         101638             1             1             40.0   \n",
       "4        80      119927451        119775             0        3832800.0   \n",
       "\n",
       "   TotLen Bwd Pkts  Fwd Pkt Len Max  Fwd Pkt Len Min  Fwd Pkt Len Mean  \\\n",
       "0              0.0              0.0              0.0               0.0   \n",
       "1              0.0              0.0              0.0               0.0   \n",
       "2              0.0              0.0              0.0               0.0   \n",
       "3            146.0             40.0             40.0              40.0   \n",
       "4              0.0             32.0             32.0              32.0   \n",
       "\n",
       "   Fwd Pkt Len Std  ...  Idle Mean  Idle Std  Idle Max  Idle Min  \\\n",
       "0              0.0  ...        0.0       0.0       0.0       0.0   \n",
       "1              0.0  ...        0.0       0.0       0.0       0.0   \n",
       "2              0.0  ...        0.0       0.0       0.0       0.0   \n",
       "3              0.0  ...        0.0       0.0       0.0       0.0   \n",
       "4              0.0  ...        0.0       0.0       0.0       0.0   \n",
       "\n",
       "                  Label  Src IP  Src Port  Dst IP  hour_of_day  day_of_week  \n",
       "0      DDOS attack-HOIC       1       0.0       0            2            2  \n",
       "1        SSH-Bruteforce       1       0.0       0            3            2  \n",
       "2        SSH-Bruteforce       1       0.0       0            2            2  \n",
       "3         Infilteration       1       0.0       0           11            2  \n",
       "4  DDOS attack-LOIC-UDP       1       0.0       0           10            2  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('preprocessed_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "940187cf-fec1-4bcc-a79c-3a50dfe7aeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-2.7.0%2Bcpu-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (27 kB)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.22.0%2Bcpu-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.7.0%2Bcpu-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./cyberenv/lib/python3.12/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: setuptools in ./cyberenv/lib/python3.12/site-packages (from torch) (80.8.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: jinja2 in ./cyberenv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy in ./cyberenv/lib/python3.12/site-packages (from torchvision) (2.2.6)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Downloading https://download.pytorch.org/whl/pillow-11.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in ./cyberenv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading https://download.pytorch.org/whl/cpu/torch-2.7.0%2Bcpu-cp312-cp312-manylinux_2_28_x86_64.whl (175.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.8/175.8 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cpu/torchvision-0.22.0%2Bcpu-cp312-cp312-manylinux_2_28_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cpu/torchaudio-2.7.0%2Bcpu-cp312-cp312-manylinux_2_28_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/pillow-11.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Downloading https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, pillow, networkx, fsspec, filelock, torch, torchvision, torchaudio\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9/9\u001b[0m [torchaudio]9\u001b[0m [torchaudio]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed filelock-3.13.1 fsspec-2024.6.1 mpmath-1.3.0 networkx-3.3 pillow-11.0.0 sympy-1.13.3 torch-2.7.0+cpu torchaudio-2.7.0+cpu torchvision-0.22.0+cpu\n",
      "Collecting pytorch-tabnet\n",
      "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in ./cyberenv/lib/python3.12/site-packages (from pytorch-tabnet) (2.2.6)\n",
      "Requirement already satisfied: scikit_learn>0.21 in ./cyberenv/lib/python3.12/site-packages (from pytorch-tabnet) (1.6.1)\n",
      "Requirement already satisfied: scipy>1.4 in ./cyberenv/lib/python3.12/site-packages (from pytorch-tabnet) (1.15.3)\n",
      "Requirement already satisfied: torch>=1.3 in ./cyberenv/lib/python3.12/site-packages (from pytorch-tabnet) (2.7.0+cpu)\n",
      "Collecting tqdm>=4.36 (from pytorch-tabnet)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./cyberenv/lib/python3.12/site-packages (from scikit_learn>0.21->pytorch-tabnet) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./cyberenv/lib/python3.12/site-packages (from scikit_learn>0.21->pytorch-tabnet) (3.6.0)\n",
      "Requirement already satisfied: filelock in ./cyberenv/lib/python3.12/site-packages (from torch>=1.3->pytorch-tabnet) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./cyberenv/lib/python3.12/site-packages (from torch>=1.3->pytorch-tabnet) (4.13.2)\n",
      "Requirement already satisfied: setuptools in ./cyberenv/lib/python3.12/site-packages (from torch>=1.3->pytorch-tabnet) (80.8.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./cyberenv/lib/python3.12/site-packages (from torch>=1.3->pytorch-tabnet) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./cyberenv/lib/python3.12/site-packages (from torch>=1.3->pytorch-tabnet) (3.3)\n",
      "Requirement already satisfied: jinja2 in ./cyberenv/lib/python3.12/site-packages (from torch>=1.3->pytorch-tabnet) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./cyberenv/lib/python3.12/site-packages (from torch>=1.3->pytorch-tabnet) (2024.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./cyberenv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./cyberenv/lib/python3.12/site-packages (from jinja2->torch>=1.3->pytorch-tabnet) (3.0.2)\n",
      "Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, pytorch-tabnet\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [pytorch-tabnet]\n",
      "\u001b[1A\u001b[2KSuccessfully installed pytorch-tabnet-4.1.0 tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1588755-6899-4862-bb3a-e404790aa640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in ./cyberenv/lib/python3.12/site-packages (from optuna) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in ./cyberenv/lib/python3.12/site-packages (from optuna) (25.0)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
      "  Downloading sqlalchemy-2.0.41-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: tqdm in ./cyberenv/lib/python3.12/site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in ./cyberenv/lib/python3.12/site-packages (from optuna) (6.0.2)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in ./cyberenv/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna)\n",
      "  Downloading greenlet-3.2.2-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in ./cyberenv/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
      "Downloading alembic-1.16.1-py3-none-any.whl (242 kB)\n",
      "Downloading sqlalchemy-2.0.41-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.2.2-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (603 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m603.9/603.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: Mako, greenlet, colorlog, sqlalchemy, alembic, optuna\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [optuna]2m5/6\u001b[0m [optuna]]my]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Mako-1.3.10 alembic-1.16.1 colorlog-6.9.0 greenlet-3.2.2 optuna-4.3.0 sqlalchemy-2.0.41\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9eacc982-e449-4fcc-b875-6864f2e5743a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/CholePuri/cyberenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eb61f07-0c8a-44a1-96b0-15189887f92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'Flow Pkts/s' in X_train contains infinite values. Replacing with 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13254/2518751553.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].replace([np.inf, -np.inf], 0, inplace=True) # You could also use X_train[col].max() if suitable\n"
     ]
    }
   ],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = df.drop('Label', axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Handle class imbalance using RandomUnderSampler\n",
    "# This will reduce the number of samples in the majority class(es)\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)\n",
    "\n",
    "# Scale numerical features\n",
    "# Identify numerical columns after encoding categorical ones\n",
    "numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Before scaling, check for and handle infinite values in numerical columns\n",
    "# Replace infinite values with a large finite number or the maximum value of the column\n",
    "# For simplicity, let's replace them with NaN first, then the existing fillna logic will handle them.\n",
    "# Or directly replace with a finite value, 0 or a calculated value.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Check for infinite values in the numerical columns of X_train\n",
    "for col in numerical_cols:\n",
    "    if np.isinf(X_train[col]).any():\n",
    "        print(f\"Column '{col}' in X_train contains infinite values. Replacing with 0.\")\n",
    "        # Replace infinite values with a finite number, e.g., 0\n",
    "        X_train[col].replace([np.inf, -np.inf], 0, inplace=True) # You could also use X_train[col].max() if suitable\n",
    "\n",
    "# Check for infinite values in the numerical columns of X_test as well, although the error was in train\n",
    "# It's good practice to ensure consistency\n",
    "for col in numerical_cols:\n",
    "    if np.isinf(X_test[col]).any():\n",
    "        print(f\"Column '{col}' in X_test contains infinite values. Replacing with 0.\")\n",
    "        X_test[col].replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b118b6f-a6ac-46c5-8585-d535d6bbc3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 12:47:27,641] A new study created in memory with name: no-name-adb3579d-6276-4e2b-b298-b1d0037eeb33\n",
      "[I 2025-05-26 12:47:27,649] Trial 0 finished with value: 0.0 and parameters: {'n_d_a': 47, 'n_steps': 5, 'gamma': 1.0341542449701877, 'lambda_sparse': 1.107429994876923e-06, 'mask_type': 'entmax', 'lr': 1.946532219615179e-05, 'batch_size': 1024, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:27,654] Trial 1 finished with value: 0.0 and parameters: {'n_d_a': 43, 'n_steps': 10, 'gamma': 1.503559397067173, 'lambda_sparse': 6.24440479977491e-06, 'mask_type': 'entmax', 'lr': 0.0004667129140245494, 'batch_size': 1024, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:27,658] Trial 2 finished with value: 0.0 and parameters: {'n_d_a': 58, 'n_steps': 8, 'gamma': 1.5880422688796219, 'lambda_sparse': 7.612427678905913e-06, 'mask_type': 'entmax', 'lr': 1.0884915113712385e-05, 'batch_size': 1024, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:27,661] Trial 3 finished with value: 0.0 and parameters: {'n_d_a': 17, 'n_steps': 5, 'gamma': 1.2580035764805348, 'lambda_sparse': 4.315554744118749e-05, 'mask_type': 'entmax', 'lr': 0.0014633122739395046, 'batch_size': 1024, 'virtual_batch_size': 128}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:27,663] Trial 4 finished with value: 0.0 and parameters: {'n_d_a': 35, 'n_steps': 10, 'gamma': 1.7876262599403903, 'lambda_sparse': 0.0006054409383940475, 'mask_type': 'sparsemax', 'lr': 0.00289674985654253, 'batch_size': 2048, 'virtual_batch_size': 128}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:27,666] Trial 5 finished with value: 0.0 and parameters: {'n_d_a': 18, 'n_steps': 3, 'gamma': 1.372220763512658, 'lambda_sparse': 0.00016445711396766388, 'mask_type': 'sparsemax', 'lr': 0.0013965228497694782, 'batch_size': 2048, 'virtual_batch_size': 128}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:27,668] Trial 6 finished with value: 0.0 and parameters: {'n_d_a': 57, 'n_steps': 5, 'gamma': 1.868228700045773, 'lambda_sparse': 1.9465846840729215e-06, 'mask_type': 'entmax', 'lr': 0.0005081620783608405, 'batch_size': 512, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:27,673] Trial 7 finished with value: 0.0 and parameters: {'n_d_a': 19, 'n_steps': 4, 'gamma': 1.2543930001483998, 'lambda_sparse': 1.017232598120902e-06, 'mask_type': 'sparsemax', 'lr': 0.0006662044137921374, 'batch_size': 1024, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:27,678] Trial 8 finished with value: 0.0 and parameters: {'n_d_a': 25, 'n_steps': 3, 'gamma': 1.2738857253558635, 'lambda_sparse': 6.902967071991712e-06, 'mask_type': 'sparsemax', 'lr': 0.0002462769663357334, 'batch_size': 512, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:27,682] Trial 9 finished with value: 0.0 and parameters: {'n_d_a': 23, 'n_steps': 4, 'gamma': 1.6065476657710955, 'lambda_sparse': 0.00035100126314308613, 'mask_type': 'entmax', 'lr': 0.00042828665073488346, 'batch_size': 512, 'virtual_batch_size': 128}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:27,716] Trial 10 finished with value: 0.0 and parameters: {'n_d_a': 45, 'n_steps': 7, 'gamma': 1.0141157427508523, 'lambda_sparse': 4.727720899202817e-05, 'mask_type': 'entmax', 'lr': 1.0178921261084127e-05, 'batch_size': 1024, 'virtual_batch_size': 256}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:27,759] Trial 11 finished with value: 0.0 and parameters: {'n_d_a': 44, 'n_steps': 10, 'gamma': 1.0095094700336245, 'lambda_sparse': 4.678171253286558e-06, 'mask_type': 'entmax', 'lr': 8.068468242985938e-05, 'batch_size': 1024, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:27,799] Trial 12 finished with value: 0.0 and parameters: {'n_d_a': 46, 'n_steps': 8, 'gamma': 1.6697081044566056, 'lambda_sparse': 3.1178716356083958e-06, 'mask_type': 'entmax', 'lr': 6.954997100436534e-05, 'batch_size': 1024, 'virtual_batch_size': 256}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:27,829] Trial 13 finished with value: 0.0 and parameters: {'n_d_a': 34, 'n_steps': 6, 'gamma': 1.9995124102197575, 'lambda_sparse': 1.4874464636353794e-05, 'mask_type': 'entmax', 'lr': 9.579746706736816e-05, 'batch_size': 1024, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 12:47:27,862] Trial 14 finished with value: 0.0 and parameters: {'n_d_a': 52, 'n_steps': 9, 'gamma': 1.4397661061810965, 'lambda_sparse': 1.1200754143506816e-06, 'mask_type': 'entmax', 'lr': 0.007405168875795538, 'batch_size': 1024, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:27,890] Trial 15 finished with value: 0.0 and parameters: {'n_d_a': 37, 'n_steps': 6, 'gamma': 1.1351451531770569, 'lambda_sparse': 1.7341132883192343e-05, 'mask_type': 'entmax', 'lr': 2.364972146575874e-05, 'batch_size': 2048, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:27,928] Trial 16 finished with value: 0.0 and parameters: {'n_d_a': 63, 'n_steps': 7, 'gamma': 1.4890446209394954, 'lambda_sparse': 2.5214495016147316e-06, 'mask_type': 'entmax', 'lr': 0.00018910475332187203, 'batch_size': 1024, 'virtual_batch_size': 256}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:27,960] Trial 17 finished with value: 0.0 and parameters: {'n_d_a': 30, 'n_steps': 9, 'gamma': 1.736705912860633, 'lambda_sparse': 1.4294275847724385e-05, 'mask_type': 'entmax', 'lr': 2.5147319259659628e-05, 'batch_size': 1024, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:27,991] Trial 18 finished with value: 0.0 and parameters: {'n_d_a': 49, 'n_steps': 5, 'gamma': 1.384710568728423, 'lambda_sparse': 1.7992132920750859e-06, 'mask_type': 'sparsemax', 'lr': 4.1602679315234265e-05, 'batch_size': 2048, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,018] Trial 19 finished with value: 0.0 and parameters: {'n_d_a': 41, 'n_steps': 8, 'gamma': 1.1436210661513933, 'lambda_sparse': 8.940967063643404e-05, 'mask_type': 'entmax', 'lr': 0.00015879195212416432, 'batch_size': 512, 'virtual_batch_size': 256}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,045] Trial 20 finished with value: 0.0 and parameters: {'n_d_a': 52, 'n_steps': 4, 'gamma': 1.5622296789096601, 'lambda_sparse': 4.9702160111371575e-06, 'mask_type': 'entmax', 'lr': 0.008632870077603601, 'batch_size': 1024, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 12:47:28,079] Trial 21 finished with value: 0.0 and parameters: {'n_d_a': 59, 'n_steps': 9, 'gamma': 1.5686635347634696, 'lambda_sparse': 8.681858729997459e-06, 'mask_type': 'entmax', 'lr': 1.1214658873746498e-05, 'batch_size': 1024, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,110] Trial 22 finished with value: 0.0 and parameters: {'n_d_a': 10, 'n_steps': 8, 'gamma': 1.659450979872429, 'lambda_sparse': 8.42855915936485e-06, 'mask_type': 'entmax', 'lr': 2.0099795355126918e-05, 'batch_size': 1024, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,141] Trial 23 finished with value: 0.0 and parameters: {'n_d_a': 56, 'n_steps': 10, 'gamma': 1.4940358860854492, 'lambda_sparse': 2.4787780905514452e-05, 'mask_type': 'entmax', 'lr': 4.7464206011778686e-05, 'batch_size': 1024, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,169] Trial 24 finished with value: 0.0 and parameters: {'n_d_a': 63, 'n_steps': 7, 'gamma': 1.4207054164821695, 'lambda_sparse': 4.00712278257068e-06, 'mask_type': 'entmax', 'lr': 0.0008591750212291806, 'batch_size': 1024, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,200] Trial 25 finished with value: 0.0 and parameters: {'n_d_a': 40, 'n_steps': 9, 'gamma': 1.3305184941966877, 'lambda_sparse': 1.6520783441901164e-06, 'mask_type': 'entmax', 'lr': 1.7316283500004957e-05, 'batch_size': 1024, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,229] Trial 26 finished with value: 0.0 and parameters: {'n_d_a': 51, 'n_steps': 6, 'gamma': 1.8389070922763935, 'lambda_sparse': 9.199645330234249e-06, 'mask_type': 'sparsemax', 'lr': 3.967766520521082e-05, 'batch_size': 1024, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,262] Trial 27 finished with value: 0.0 and parameters: {'n_d_a': 55, 'n_steps': 8, 'gamma': 1.1447299155289046, 'lambda_sparse': 2.7577196770055243e-05, 'mask_type': 'entmax', 'lr': 0.00014021752948574352, 'batch_size': 1024, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 12:47:28,291] Trial 28 finished with value: 0.0 and parameters: {'n_d_a': 48, 'n_steps': 10, 'gamma': 1.6845233298719013, 'lambda_sparse': 7.379951421515153e-05, 'mask_type': 'entmax', 'lr': 0.0003167740457162252, 'batch_size': 2048, 'virtual_batch_size': 128}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,317] Trial 29 finished with value: 0.0 and parameters: {'n_d_a': 40, 'n_steps': 5, 'gamma': 1.5222952072544529, 'lambda_sparse': 6.152994702436254e-06, 'mask_type': 'entmax', 'lr': 0.0016581206651859466, 'batch_size': 512, 'virtual_batch_size': 256}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,344] Trial 30 finished with value: 0.0 and parameters: {'n_d_a': 59, 'n_steps': 6, 'gamma': 1.2345906864175764, 'lambda_sparse': 2.7288779671036574e-06, 'mask_type': 'entmax', 'lr': 1.4910383258143937e-05, 'batch_size': 1024, 'virtual_batch_size': 128}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,373] Trial 31 finished with value: 0.0 and parameters: {'n_d_a': 33, 'n_steps': 5, 'gamma': 1.068264892280559, 'lambda_sparse': 4.728846607192694e-05, 'mask_type': 'entmax', 'lr': 0.004871119101577616, 'batch_size': 1024, 'virtual_batch_size': 128}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,410] Trial 32 finished with value: 0.0 and parameters: {'n_d_a': 12, 'n_steps': 4, 'gamma': 1.2868866267656882, 'lambda_sparse': 0.0008002633641135689, 'mask_type': 'sparsemax', 'lr': 0.0020761544604631084, 'batch_size': 1024, 'virtual_batch_size': 128}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,436] Trial 33 finished with value: 0.0 and parameters: {'n_d_a': 28, 'n_steps': 5, 'gamma': 1.1975906218108343, 'lambda_sparse': 3.708805436144076e-05, 'mask_type': 'entmax', 'lr': 0.0009294844748921872, 'batch_size': 2048, 'virtual_batch_size': 128}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,462] Trial 34 finished with value: 0.0 and parameters: {'n_d_a': 16, 'n_steps': 3, 'gamma': 1.3395891292154247, 'lambda_sparse': 0.00016869313019880143, 'mask_type': 'sparsemax', 'lr': 0.0036086651378082926, 'batch_size': 1024, 'virtual_batch_size': 128}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,493] Trial 35 finished with value: 0.0 and parameters: {'n_d_a': 42, 'n_steps': 7, 'gamma': 1.0858706636837943, 'lambda_sparse': 0.00018371830096667672, 'mask_type': 'entmax', 'lr': 0.0011971553406319609, 'batch_size': 1024, 'virtual_batch_size': 128}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 12:47:28,526] Trial 36 finished with value: 0.0 and parameters: {'n_d_a': 37, 'n_steps': 4, 'gamma': 1.4439701069078255, 'lambda_sparse': 2.0306315520362545e-05, 'mask_type': 'entmax', 'lr': 0.0006098084640255853, 'batch_size': 512, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,552] Trial 37 finished with value: 0.0 and parameters: {'n_d_a': 23, 'n_steps': 6, 'gamma': 1.6139649149136497, 'lambda_sparse': 8.18917594182019e-05, 'mask_type': 'sparsemax', 'lr': 0.0032715770558118203, 'batch_size': 1024, 'virtual_batch_size': 128}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,573] Trial 38 finished with value: 0.0 and parameters: {'n_d_a': 19, 'n_steps': 10, 'gamma': 1.1967344112132396, 'lambda_sparse': 1.0794869596716814e-05, 'mask_type': 'entmax', 'lr': 0.0002870694613390964, 'batch_size': 2048, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,598] Trial 39 finished with value: 0.0 and parameters: {'n_d_a': 46, 'n_steps': 5, 'gamma': 1.3082849388968012, 'lambda_sparse': 1.2736974503179377e-06, 'mask_type': 'entmax', 'lr': 0.0004230219390412484, 'batch_size': 512, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,627] Trial 40 finished with value: 0.0 and parameters: {'n_d_a': 54, 'n_steps': 3, 'gamma': 1.7996182300141972, 'lambda_sparse': 5.4052459349076046e-05, 'mask_type': 'entmax', 'lr': 3.0726952340839886e-05, 'batch_size': 1024, 'virtual_batch_size': 256}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,655] Trial 41 finished with value: 0.0 and parameters: {'n_d_a': 15, 'n_steps': 10, 'gamma': 1.384579436691854, 'lambda_sparse': 0.0007106205849691455, 'mask_type': 'sparsemax', 'lr': 0.002140560521431632, 'batch_size': 2048, 'virtual_batch_size': 128}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,684] Trial 42 finished with value: 0.0 and parameters: {'n_d_a': 26, 'n_steps': 9, 'gamma': 1.940095982425936, 'lambda_sparse': 0.0003067192365242056, 'mask_type': 'sparsemax', 'lr': 0.002937283002968144, 'batch_size': 2048, 'virtual_batch_size': 128}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,711] Trial 43 finished with value: 0.0 and parameters: {'n_d_a': 32, 'n_steps': 10, 'gamma': 1.7428474197792374, 'lambda_sparse': 0.0004276945666399231, 'mask_type': 'sparsemax', 'lr': 0.005433615265936431, 'batch_size': 2048, 'virtual_batch_size': 128}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 12:47:28,743] Trial 44 finished with value: 0.0 and parameters: {'n_d_a': 43, 'n_steps': 9, 'gamma': 1.9151230285541057, 'lambda_sparse': 3.896003723565871e-06, 'mask_type': 'sparsemax', 'lr': 0.0010394526350858426, 'batch_size': 2048, 'virtual_batch_size': 128}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,775] Trial 45 finished with value: 0.0 and parameters: {'n_d_a': 38, 'n_steps': 8, 'gamma': 1.738479047486464, 'lambda_sparse': 6.227932189282702e-06, 'mask_type': 'sparsemax', 'lr': 0.0015983597983872352, 'batch_size': 1024, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,802] Trial 46 finished with value: 0.0 and parameters: {'n_d_a': 59, 'n_steps': 10, 'gamma': 1.0447723060913388, 'lambda_sparse': 2.1210757408237577e-06, 'mask_type': 'entmax', 'lr': 0.0006746110554126594, 'batch_size': 1024, 'virtual_batch_size': 128}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,828] Trial 47 finished with value: 0.0 and parameters: {'n_d_a': 48, 'n_steps': 9, 'gamma': 1.8005047424218577, 'lambda_sparse': 0.00012125797548863362, 'mask_type': 'entmax', 'lr': 1.3493650484949014e-05, 'batch_size': 1024, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,855] Trial 48 finished with value: 0.0 and parameters: {'n_d_a': 8, 'n_steps': 7, 'gamma': 1.630996006658524, 'lambda_sparse': 1.4777855676937562e-05, 'mask_type': 'sparsemax', 'lr': 0.00010333344512248033, 'batch_size': 2048, 'virtual_batch_size': 256}. Best is trial 0 with value: 0.0.\n",
      "[I 2025-05-26 12:47:28,889] Trial 49 finished with value: 0.0 and parameters: {'n_d_a': 45, 'n_steps': 5, 'gamma': 1.5392393856928428, 'lambda_sparse': 0.0002497975583070585, 'mask_type': 'entmax', 'lr': 0.00039738448573851595, 'batch_size': 512, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Trial failed with error: name 'X_train_np' is not defined\n",
      "Best trial:\n",
      "  Value: 0.0\n",
      "  Params: \n",
      "    n_d_a: 47\n",
      "    n_steps: 5\n",
      "    gamma: 1.0341542449701877\n",
      "    lambda_sparse: 1.107429994876923e-06\n",
      "    mask_type: entmax\n",
      "    lr: 1.946532219615179e-05\n",
      "    batch_size: 1024\n",
      "    virtual_batch_size: 64\n",
      "\n",
      "Training final model with best parameters:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train_np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 115\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# Train the final model with more epochs\u001b[39;00m\n\u001b[32m    114\u001b[39m final_clf.fit(\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     X_train=\u001b[43mX_train_np\u001b[49m, y_train=y_train_np,\n\u001b[32m    116\u001b[39m     eval_set=[(X_train_np, y_train_np), (X_test_np, y_test_np)],  \u001b[38;5;66;03m# Include train & test for plotting\u001b[39;00m\n\u001b[32m    117\u001b[39m     eval_name=[\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    118\u001b[39m     max_epochs=\u001b[32m300\u001b[39m,          \u001b[38;5;66;03m# Increased to 300 as requested\u001b[39;00m\n\u001b[32m    119\u001b[39m     patience=\u001b[32m50\u001b[39m,             \u001b[38;5;66;03m# You can adjust this as needed\u001b[39;00m\n\u001b[32m    120\u001b[39m     batch_size=best_params[\u001b[33m'\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    121\u001b[39m     virtual_batch_size=best_params[\u001b[33m'\u001b[39m\u001b[33mvirtual_batch_size\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    122\u001b[39m     num_workers=\u001b[32m0\u001b[39m,\n\u001b[32m    123\u001b[39m     drop_last=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    124\u001b[39m )\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# Evaluate the final model\u001b[39;00m\n\u001b[32m    127\u001b[39m final_preds = final_clf.predict(X_test_np)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train_np' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    # TabNet specific hyperparameters\n",
    "    n_d_a = trial.suggest_int('n_d_a', 8, 64) # Common size for attention and decision layers\n",
    "    n_steps = trial.suggest_int('n_steps', 3, 10)\n",
    "    gamma = trial.suggest_float('gamma', 1.0, 2.0) # Higher gamma means more importance to previous step's attention\n",
    "    lambda_sparse = trial.suggest_float('lambda_sparse', 1e-6, 1e-3, log=True) # Controls sparsity\n",
    "    mask_type = trial.suggest_categorical('mask_type', ['sparsemax', 'entmax'])\n",
    "\n",
    "    # Optimizer hyperparameters\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "\n",
    "    # Training parameters (can also be tuned, but start with model params)\n",
    "    max_epochs = 100 # Reduce epochs for faster tuning, then train with more\n",
    "    patience = 20 # Patience for early stopping\n",
    "    batch_size = trial.suggest_categorical('batch_size', [512, 1024, 2048])\n",
    "    virtual_batch_size = trial.suggest_categorical('virtual_batch_size', [64, 128, 256])\n",
    "\n",
    "\n",
    "    # Create and train the TabNet model with suggested hyperparameters\n",
    "    model = TabNetClassifier(\n",
    "        n_d=n_d_a,\n",
    "        n_a=n_d_a,\n",
    "        n_steps=n_steps,\n",
    "        gamma=gamma,\n",
    "        lambda_sparse=lambda_sparse,\n",
    "        mask_type=mask_type,\n",
    "        optimizer_fn=torch.optim.Adam,\n",
    "        optimizer_params=dict(lr=lr),\n",
    "        scheduler_params={\"step_size\":20, \"gamma\":0.9}, # Keep scheduler simple for now\n",
    "        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "        verbose=0 # Suppress verbose output during tuning\n",
    "    )\n",
    "\n",
    "    # Convert data to numpy arrays (already done in the original code block, but good to be explicit in the function)\n",
    "    # Ensure X_train_np, y_train_np, X_test_np, y_test_np are accessible in this scope\n",
    "    # Since this objective function will likely be run within the same notebook session,\n",
    "    # the global variables defined in the previous cell should be available.\n",
    "\n",
    "    try:\n",
    "        model.fit(\n",
    "            X_train=X_train_np, y_train=y_train_np,\n",
    "            eval_set=[(X_test_np, y_test_np)],\n",
    "            eval_name=['test'],\n",
    "            max_epochs=max_epochs,\n",
    "            patience=patience,\n",
    "            batch_size=batch_size,\n",
    "            virtual_batch_size=virtual_batch_size,\n",
    "            num_workers=0,\n",
    "            drop_last=False\n",
    "        )\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "        preds = model.predict(X_test_np)\n",
    "\n",
    "        # Calculate the metric to optimize. Accuracy is simple, but for imbalanced data,\n",
    "        # F1-score or ROC AUC might be better. Let's use accuracy for now as requested,\n",
    "        # but keep in mind other metrics.\n",
    "        accuracy = accuracy_score(y_test_np, preds)\n",
    "\n",
    "        # You could also return other metrics:\n",
    "        # f1 = f1_score(y_test_np, preds, average='weighted') # or 'macro', 'micro'\n",
    "        # roc_auc = roc_auc_score(y_test_np, model.predict_proba(X_test_np), multi_class='ovr') # ovr or ovo\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle potential errors during training (e.g., CUDA out of memory)\n",
    "        # Returning a very low value discourages Optuna from exploring this configuration\n",
    "        print(f\"Trial failed with error: {e}\")\n",
    "        return 0.0 # Or np.nan, depending on Optuna version/settings\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction='maximize') # We want to maximize accuracy\n",
    "\n",
    "# Run the optimization\n",
    "# n_trials: number of different hyperparameter combinations to try\n",
    "# timeout: maximum time in seconds to run the study\n",
    "study.optimize(objective, n_trials=50, timeout=600) # Run 50 trials, max 10 minutes\n",
    "\n",
    "# Print the best hyperparameters and the corresponding best score\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f\"  Value: {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# You can access the best model parameters from study.best_params and\n",
    "# train your final model using these parameters on the full training data (or train + validation data if you split differently).\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"\\nTraining final model with best parameters:\")\n",
    "final_clf = TabNetClassifier(\n",
    "    n_d=best_params['n_d_a'],\n",
    "    n_a=best_params['n_d_a'],\n",
    "    n_steps=best_params['n_steps'],\n",
    "    gamma=best_params['gamma'],\n",
    "    lambda_sparse=best_params['lambda_sparse'],\n",
    "    mask_type=best_params['mask_type'],\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=best_params['lr']),\n",
    "    scheduler_params={\"step_size\":50, \"gamma\":0.9}, # Use the original scheduler or tune this too\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    verbose=1 # Keep verbose for final training\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train the final model with more epochs\n",
    "final_clf.fit(\n",
    "    X_train=X_train_np, y_train=y_train_np,\n",
    "    eval_set=[(X_train_np, y_train_np), (X_test_np, y_test_np)],  # Include train & test for plotting\n",
    "    eval_name=['train', 'test'],\n",
    "    max_epochs=300,          # Increased to 300 as requested\n",
    "    patience=50,             # You can adjust this as needed\n",
    "    batch_size=best_params['batch_size'],\n",
    "    virtual_batch_size=best_params['virtual_batch_size'],\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "# Evaluate the final model\n",
    "final_preds = final_clf.predict(X_test_np)\n",
    "final_accuracy = accuracy_score(y_test_np, final_preds)\n",
    "print(f\"\\nFinal model accuracy with best hyperparameters: {final_accuracy}\")\n",
    "\n",
    "# ========== Plotting Train vs Validation Accuracy ==========\n",
    "# Extract logs\n",
    "train_acc = final_clf.history['train_accuracy']\n",
    "valid_acc = final_clf.history['test_accuracy']  # 'test' is the name you assigned in eval_name\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_acc, label='Train Accuracy')\n",
    "plt.plot(valid_acc, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Train vs Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ef0b73-3c53-4f3e-a180-1aeead7a695f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cyberenv)",
   "language": "python",
   "name": "cyberenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
